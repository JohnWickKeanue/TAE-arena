{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPavNTGOpE881l/bZTQnJ77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnWickKeanue/TAE-arena/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilFhXmTSDI6w"
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "#@title <b><center>Enter taemovies link</center></b>\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from requests import get\n",
        "url = \"https://taemovies.blogspot.com/2022/11/transformers-2007-bluray-1080p-720p-avc.html?m=1\"#@param {type:\"string\"}\n",
        "\n",
        "def flix(url):\n",
        "    client = requests.session()\n",
        "    r = client.get(url).text\n",
        "    soup = BeautifulSoup (r, \"html.parser\")\n",
        "    for a in soup.find_all(\"a\"):\n",
        "                   c = a.get(\"href\")\n",
        "                  \n",
        "                   if \"shortingly\" in c:\n",
        "                       \n",
        "                       code = c.split(\"/\")[-1]\n",
        "                       DOMAIN = \"https://go.techyjeeshan.xyz\"\n",
        "                       \n",
        "                       final_url = f\"{DOMAIN}/{code}\"\n",
        "                       resp = client.get(final_url)\n",
        "                       soup = BeautifulSoup(resp.content, \"html.parser\")\n",
        "    \n",
        "                       try: inputs = soup.find(id=\"go-link\").find_all(name=\"input\")\n",
        "                       except: return \"Incorrect Link\"\n",
        "    \n",
        "                       data = { input.get('name'): input.get('value') for input in inputs }\n",
        "\n",
        "                       h = { \"x-requested-with\": \"XMLHttpRequest\" }\n",
        "    \n",
        "                       time.sleep(10)\n",
        "                       r = client.post(f\"{DOMAIN}/links/go\", data=data, headers=h)\n",
        "                       g = r.json()['url']\n",
        "                       \n",
        "                       t = client.get(g).text\n",
        "                       soupt = BeautifulSoup(t, \"html.parser\")\n",
        "                       title = soupt.title\n",
        "                       gd_txt = f\"{(title.text).replace('GDToT | ' , '')}\\n{g}\\n\\n\"\n",
        "                       print(gd_txt)\n",
        "\n",
        "print(flix(url))"
      ]
    }
  ]
}